{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxdc2Q235NyI",
    "outputId": "5d5a2aed-e1ae-45f2-9645-fb305d89814b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMnIebVgsKcb"
   },
   "source": [
    "# Preprocessing for unseen_nominal_logs plus unseen_logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKGOF85B415h"
   },
   "outputs": [],
   "source": [
    "cd drive/MyDrive/SNN_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMXPRcR605at"
   },
   "outputs": [],
   "source": [
    " # Go to that directory where log files are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iwm561PkPXLe"
   },
   "outputs": [],
   "source": [
    " cd Column128_seq/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYDAgvgVPLi8"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_tArxWR2NO4"
   },
   "outputs": [],
   "source": [
    "import os,re, pickle, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSEgnp7T2Nbw"
   },
   "outputs": [],
   "source": [
    "def getInfo(file, ip_spks):\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    file : Log files \n",
    "    ip_spks : Number of input neurons or pre-synaptic neurons\n",
    "\n",
    "    return :\n",
    "    df : Dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    with open(file) as f:\n",
    "        soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Making column names\n",
    "    cols = [\"Time(s)\", \"Column Number\"]\n",
    "    for i in range(ip_spks):\n",
    "      cols.append(\"spk_ip_\" + str(i))\n",
    "      cols.append(\"#Spikes_\" + str(i))\n",
    "      cols.append(\"ISI_\" + str(i))\n",
    "\n",
    "    cols += [\"#Spikes_out\", \"ISI_out\"]\n",
    "\n",
    "    time = [int(i.split(\":\")[1]) for i in re.findall(r\"Time : \\d+\", soup.text)]\n",
    "\n",
    "    df[\"Time(s)\"] = time\n",
    "\n",
    "    # Column number info\n",
    "    col_num = [int(j.split(\":\")[1]) for j in re.findall(\"Column number: \\d+\",soup.text)]\n",
    "\n",
    "    df[\"Column Number\"] = col_num \n",
    "\n",
    "    # NeuronID info for each spike generating neuron\n",
    "    n_id_info = re.findall(\"NeuronID: (.+)\", soup.text)\n",
    "\n",
    "    spikes_info = [list(map(int,re.findall(r'(\\d+)', i))) for i in n_id_info]\n",
    "    \n",
    "    n_id_info_v1 = []\n",
    "\n",
    "    for idx in range(0, len(spikes_info), ip_spks):\n",
    "      \n",
    "      var = list(chain.from_iterable((x[0],len(x)-1, x[1:]) for x in spikes_info[idx: idx + ip_spks]))\n",
    "      \n",
    "      n_id_info_v1.append(var)\n",
    "  \n",
    "\n",
    "    df[cols[2:-2]] = n_id_info_v1\n",
    "\n",
    "\n",
    "    # Output column info\n",
    "    out = re.findall(\"Output Neuron at column (.+)\", soup.text)\n",
    "\n",
    "    spikes_info_out = [list(map(int, re.findall(r'(\\d+)', i))) for i in out]\n",
    "    # print(spikes_info_out)\n",
    "    out_info = []\n",
    "\n",
    "    for i_out in spikes_info_out:\n",
    "      out_info.append([len(i_out)-1, i_out[1:]])\n",
    "\n",
    "    # Checking #instances\n",
    "    assert len(out_info) == len(time) == len(col_num) == len(n_id_info_v1)\n",
    "    \n",
    "    df[cols[-2:]] = out_info\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mV4_qvJ2Ned"
   },
   "outputs": [],
   "source": [
    "# To compute average ISI (Inter-spiking interval)\n",
    "def getAvgIsi(x):\n",
    "\n",
    "  if len(x) == 1:\n",
    "    return x[0]%1000\n",
    "\n",
    "  else:\n",
    "    return sum([(x[i+1]%1000)- (x[i]%1000) for i in range(len(x)-1)])/(len(x)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4MVxTeX2Njb"
   },
   "outputs": [],
   "source": [
    "def SaveRawFile(dataframe, i, fol, dir_name):\n",
    "  \"\"\"\n",
    "  Args :\n",
    "  dataframe: Dataframe\n",
    "  i : Post-synaptic neuron ID\n",
    "  fol : File name of post-synaptic neuron ID\n",
    "  dir_name : Directory name where formatted logs will be saved\n",
    "  \n",
    "  \"\"\"\n",
    "\n",
    "  columns = dataframe.columns\n",
    "  f = pd.DataFrame()\n",
    "\n",
    "  idx = 0\n",
    "  for e in columns:\n",
    "    \n",
    "    if e.startswith(\"ISI_\"):\n",
    "\n",
    "      if e == \"ISI_out\":\n",
    "          f[e] =  dataframe[e]\n",
    "          f['Avg_ISI_out'] =  dataframe['ISI_out'].apply(lambda x: getAvgIsi(x))\n",
    "        \n",
    "      else:\n",
    "        f[e] =  dataframe[e]\n",
    "        f['Avg_ISI_'+str(idx)] =  dataframe['ISI_' + str(idx)].apply(lambda x: getAvgIsi(x))\n",
    "        idx += 1\n",
    "\n",
    "    else:\n",
    "      f[e] = dataframe[e]\n",
    "\n",
    "  f.to_excel(dir_name + \"/\" + fol + \"/\" + \"Column\" + str(i) + \".xlsx\", index = False)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiXb1EHY2NmS",
    "outputId": "4fd4bb3f-eef8-4c62-a552-ec87452f21e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column_43', 'Column_19', 'Column_16', 'Column_79', 'Column_26', 'Column_30', 'Column_100', 'Column_29', 'Column_124', 'Column_97', 'Column_77', 'Column_111', 'Column_37', 'Column_33', 'Column_17', 'Column_56', 'Column_1', 'Column_81', 'Column_32', 'Column_105', 'Column_95', 'Column_99', 'Column_115', 'Column_27', 'Column_2', 'Column_34', 'Column_116', 'Column_38', 'Column_9', 'Column_104', 'Column_35', 'Column_121', 'Column_114', 'Column_31', 'Column_57', 'Column_68', 'Column_59', 'Column_94', 'Column_84', 'Column_119', 'Column_40', 'Column_122', 'Column_126', 'Column_92', 'Column_20', 'Column_24', 'Column_36', 'Column_74', 'Column_96', 'Column_6', 'Column_85', 'Column_47', 'Column_82', 'Column_22', 'Column_48', 'Column_98', 'Column_90', 'Column_41', 'Column_106', 'Column_91', 'Column_28', 'Column_72', 'Column_118', 'Column_25', 'Column_101', 'Column_109', 'Column_62', 'Column_10', 'Column_12', 'Column_60', 'Column_42', 'Column_73', 'Column_21', 'Column_64', 'Column_23', 'Column_11', 'Column_113', 'Column_89', 'Column_66', 'Column_7', 'Column_70', 'Column_61', 'Column_86', 'Column_14', 'Column_87', 'Column_15', 'Column_127', 'Column_69', 'Column_0', 'Column_52', 'Column_4', 'Column_44', 'Column_83', 'Column_102', 'Column_45', 'Column_5', 'Column_93', 'Column_88', 'Column_78', 'Column_3', 'Column_123', 'Column_75', 'Column_71', 'Column_117', 'Column_55', 'Column_120', 'Column_63', 'Column_80', 'Column_51', 'Column_110', 'Column_67', 'Column_107', 'Column_46', 'Column_53', 'Column_108', 'Column_58', 'Column_8', 'Column_50', 'Column_112', 'Column_18', 'Column_76', 'Column_103', 'Column_54', 'Column_65', 'Column_13', 'Column_39', 'Column_125', 'Column_49']\n"
     ]
    }
   ],
   "source": [
    "fol_name = os.listdir(\"Unseen_nominal_logs/\")\n",
    "assert len(fol_name) == 128\n",
    "print(fol_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNj0VjnXsbHi"
   },
   "outputs": [],
   "source": [
    "# To make a directory to save all unseen nominal log files for each pre-synaptic neuron or input neuron\n",
    "os.mkdir(\"files_128_nominal_raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4RXs9QW4Tof"
   },
   "source": [
    "# Saving log files in the desirable and readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uG5abex2Nov",
    "outputId": "25496da2-9898-40a5-cbdb-6dabf2c6f385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Name : Column_43 | Column name : log_weight43.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3678: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = igetitem(value, i)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Name : Column_19 | Column name : log_weight19.txt.\n",
      "Folder Name : Column_16 | Column name : log_weight16.txt.\n",
      "Folder Name : Column_79 | Column name : log_weight79.txt.\n",
      "Folder Name : Column_26 | Column name : log_weight26.txt.\n",
      "Folder Name : Column_30 | Column name : log_weight30.txt.\n",
      "Folder Name : Column_100 | Column name : log_weight100.txt.\n",
      "Folder Name : Column_29 | Column name : log_weight29.txt.\n",
      "Folder Name : Column_124 | Column name : log_weight124.txt.\n",
      "Folder Name : Column_97 | Column name : log_weight97.txt.\n",
      "Folder Name : Column_77 | Column name : log_weight77.txt.\n",
      "Folder Name : Column_111 | Column name : log_weight111.txt.\n",
      "Folder Name : Column_37 | Column name : log_weight37.txt.\n",
      "Folder Name : Column_33 | Column name : log_weight33.txt.\n",
      "Folder Name : Column_17 | Column name : log_weight17.txt.\n",
      "Folder Name : Column_56 | Column name : log_weight56.txt.\n",
      "Folder Name : Column_1 | Column name : log_weight1.txt.\n",
      "Folder Name : Column_81 | Column name : log_weight81.txt.\n",
      "Folder Name : Column_32 | Column name : log_weight32.txt.\n",
      "Folder Name : Column_105 | Column name : log_weight105.txt.\n",
      "Folder Name : Column_95 | Column name : log_weight95.txt.\n",
      "Folder Name : Column_99 | Column name : log_weight99.txt.\n",
      "Folder Name : Column_115 | Column name : log_weight115.txt.\n",
      "Folder Name : Column_27 | Column name : log_weight27.txt.\n",
      "Folder Name : Column_2 | Column name : log_weight2.txt.\n",
      "Folder Name : Column_34 | Column name : log_weight34.txt.\n",
      "Folder Name : Column_116 | Column name : log_weight116.txt.\n",
      "Folder Name : Column_38 | Column name : log_weight38.txt.\n",
      "Folder Name : Column_9 | Column name : log_weight9.txt.\n",
      "Folder Name : Column_104 | Column name : log_weight104.txt.\n",
      "Folder Name : Column_35 | Column name : log_weight35.txt.\n",
      "Folder Name : Column_121 | Column name : log_weight121.txt.\n",
      "Folder Name : Column_114 | Column name : log_weight114.txt.\n",
      "Folder Name : Column_31 | Column name : log_weight31.txt.\n",
      "Folder Name : Column_57 | Column name : log_weight57.txt.\n",
      "Folder Name : Column_68 | Column name : log_weight68.txt.\n",
      "Folder Name : Column_59 | Column name : log_weight59.txt.\n",
      "Folder Name : Column_94 | Column name : log_weight94.txt.\n",
      "Folder Name : Column_84 | Column name : log_weight84.txt.\n",
      "Folder Name : Column_119 | Column name : log_weight119.txt.\n",
      "Folder Name : Column_40 | Column name : log_weight40.txt.\n",
      "Folder Name : Column_122 | Column name : log_weight122.txt.\n",
      "Folder Name : Column_126 | Column name : log_weight126.txt.\n",
      "Folder Name : Column_92 | Column name : log_weight92.txt.\n",
      "Folder Name : Column_20 | Column name : log_weight20.txt.\n",
      "Folder Name : Column_24 | Column name : log_weight24.txt.\n",
      "Folder Name : Column_36 | Column name : log_weight36.txt.\n",
      "Folder Name : Column_74 | Column name : log_weight74.txt.\n",
      "Folder Name : Column_96 | Column name : log_weight96.txt.\n",
      "Folder Name : Column_6 | Column name : log_weight6.txt.\n",
      "Folder Name : Column_85 | Column name : log_weight85.txt.\n",
      "Folder Name : Column_47 | Column name : log_weight47.txt.\n",
      "Folder Name : Column_82 | Column name : log_weight82.txt.\n",
      "Folder Name : Column_22 | Column name : log_weight22.txt.\n",
      "Folder Name : Column_48 | Column name : log_weight48.txt.\n",
      "Folder Name : Column_98 | Column name : log_weight98.txt.\n",
      "Folder Name : Column_90 | Column name : log_weight90.txt.\n",
      "Folder Name : Column_41 | Column name : log_weight41.txt.\n",
      "Folder Name : Column_106 | Column name : log_weight106.txt.\n",
      "Folder Name : Column_91 | Column name : log_weight91.txt.\n",
      "Folder Name : Column_28 | Column name : log_weight28.txt.\n",
      "Folder Name : Column_72 | Column name : log_weight72.txt.\n",
      "Folder Name : Column_118 | Column name : log_weight118.txt.\n",
      "Folder Name : Column_25 | Column name : log_weight25.txt.\n",
      "Folder Name : Column_101 | Column name : log_weight101.txt.\n",
      "Folder Name : Column_109 | Column name : log_weight109.txt.\n",
      "Folder Name : Column_62 | Column name : log_weight62.txt.\n",
      "Folder Name : Column_10 | Column name : log_weight10.txt.\n",
      "Folder Name : Column_12 | Column name : log_weight12.txt.\n",
      "Folder Name : Column_60 | Column name : log_weight60.txt.\n",
      "Folder Name : Column_42 | Column name : log_weight42.txt.\n",
      "Folder Name : Column_73 | Column name : log_weight73.txt.\n",
      "Folder Name : Column_21 | Column name : log_weight21.txt.\n",
      "Folder Name : Column_64 | Column name : log_weight64.txt.\n",
      "Folder Name : Column_23 | Column name : log_weight23.txt.\n",
      "Folder Name : Column_11 | Column name : log_weight11.txt.\n",
      "Folder Name : Column_113 | Column name : log_weight113.txt.\n",
      "Folder Name : Column_89 | Column name : log_weight89.txt.\n",
      "Folder Name : Column_66 | Column name : log_weight66.txt.\n",
      "Folder Name : Column_7 | Column name : log_weight7.txt.\n",
      "Folder Name : Column_70 | Column name : log_weight70.txt.\n",
      "Folder Name : Column_61 | Column name : log_weight61.txt.\n",
      "Folder Name : Column_86 | Column name : log_weight86.txt.\n",
      "Folder Name : Column_14 | Column name : log_weight14.txt.\n",
      "Folder Name : Column_87 | Column name : log_weight87.txt.\n",
      "Folder Name : Column_15 | Column name : log_weight15.txt.\n",
      "Folder Name : Column_127 | Column name : log_weight127.txt.\n",
      "Folder Name : Column_69 | Column name : log_weight69.txt.\n",
      "Folder Name : Column_0 | Column name : log_weight0.txt.\n",
      "Folder Name : Column_52 | Column name : log_weight52.txt.\n",
      "Folder Name : Column_4 | Column name : log_weight4.txt.\n",
      "Folder Name : Column_44 | Column name : log_weight44.txt.\n",
      "Folder Name : Column_83 | Column name : log_weight83.txt.\n",
      "Folder Name : Column_102 | Column name : log_weight102.txt.\n",
      "Folder Name : Column_45 | Column name : log_weight45.txt.\n",
      "Folder Name : Column_5 | Column name : log_weight5.txt.\n",
      "Folder Name : Column_93 | Column name : log_weight93.txt.\n",
      "Folder Name : Column_88 | Column name : log_weight88.txt.\n",
      "Folder Name : Column_78 | Column name : log_weight78.txt.\n",
      "Folder Name : Column_3 | Column name : log_weight3.txt.\n",
      "Folder Name : Column_123 | Column name : log_weight123.txt.\n",
      "Folder Name : Column_75 | Column name : log_weight75.txt.\n",
      "Folder Name : Column_71 | Column name : log_weight71.txt.\n",
      "Folder Name : Column_117 | Column name : log_weight117.txt.\n",
      "Folder Name : Column_55 | Column name : log_weight55.txt.\n",
      "Folder Name : Column_120 | Column name : log_weight120.txt.\n",
      "Folder Name : Column_63 | Column name : log_weight63.txt.\n",
      "Folder Name : Column_80 | Column name : log_weight80.txt.\n",
      "Folder Name : Column_51 | Column name : log_weight51.txt.\n",
      "Folder Name : Column_110 | Column name : log_weight110.txt.\n",
      "Folder Name : Column_67 | Column name : log_weight67.txt.\n",
      "Folder Name : Column_107 | Column name : log_weight107.txt.\n",
      "Folder Name : Column_46 | Column name : log_weight46.txt.\n",
      "Folder Name : Column_53 | Column name : log_weight53.txt.\n",
      "Folder Name : Column_108 | Column name : log_weight108.txt.\n",
      "Folder Name : Column_58 | Column name : log_weight58.txt.\n",
      "Folder Name : Column_8 | Column name : log_weight8.txt.\n",
      "Folder Name : Column_50 | Column name : log_weight50.txt.\n",
      "Folder Name : Column_112 | Column name : log_weight112.txt.\n",
      "Folder Name : Column_18 | Column name : log_weight18.txt.\n",
      "Folder Name : Column_76 | Column name : log_weight76.txt.\n",
      "Folder Name : Column_103 | Column name : log_weight103.txt.\n",
      "Folder Name : Column_54 | Column name : log_weight54.txt.\n",
      "Folder Name : Column_65 | Column name : log_weight65.txt.\n",
      "Folder Name : Column_13 | Column name : log_weight13.txt.\n",
      "Folder Name : Column_39 | Column name : log_weight39.txt.\n",
      "Folder Name : Column_125 | Column name : log_weight125.txt.\n",
      "Folder Name : Column_49 | Column name : log_weight49.txt.\n"
     ]
    }
   ],
   "source": [
    "for var in [(\"files_128_nominal_raw\", \"Unseen_nominal_logs/\")]:\n",
    "\n",
    "  dir_name, unseen_log = var\n",
    "  for fol in fol_name:\n",
    "      logs_list = [i for i in os.listdir(unseen_log + fol) if i.endswith(\".txt\")]\n",
    "\n",
    "      os.mkdir(dir_name + \"/\"+ fol) \n",
    "\n",
    "      # Saving raw data in excel file\n",
    "      for file_name in logs_list:\n",
    "        print(f\"Folder Name : {fol} | Column name : {file_name}.\")\n",
    "        col_num = int(file_name.split(\".txt\")[0][10:])\n",
    "        df = getInfo(unseen_log + fol + \"/\" + file_name, 128)\n",
    "        SaveRawFile(df, col_num, fol, dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwHPqUbL2NrW"
   },
   "outputs": [],
   "source": [
    "# Sort the name of file of post-synaptic neuron ID\n",
    "\n",
    "def atof(text):\n",
    "    try:\n",
    "        retval = float(text)\n",
    "    except ValueError:\n",
    "        retval = text\n",
    "    return retval\n",
    "\n",
    "def natural_keys(text):\n",
    "\n",
    "    return [ atof(c) for c in re.split(r'[+-]?([0-9]+(?:[.][0-9]*)?|[.][0-9]+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7sdcsgl2Nuf"
   },
   "outputs": [],
   "source": [
    "# To create a directory to save all features (Spike rate, Avg. ISI) and their ground truth (Observed ISI) \n",
    "os.mkdir(\"StackedFiles_nominal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRBTQEnz2Nwt"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracting features (Spike rate, Avg. ISI) and their ground truth (Observed ISI) and then\n",
    "apply breakout distribution and then data augmentation.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def StackedFile(path, nG, fol, dirName, numCp):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    path : File name path for post-synaptic neuron ID\n",
    "    nG : Number of post-synaptic neurons\n",
    "    fol : post-synaptic neuron ID\n",
    "    dirName : Directory name where stacked files will be saved\n",
    "    numCp : Number of mapped crosspoints\n",
    "\n",
    "    \"\"\"\n",
    "    files = [i for i in os.listdir(path) if i.endswith(\".xlsx\")]\n",
    "    files.sort(key=natural_keys)  \n",
    "\n",
    "    # print(files, files[0].split('.xlsx')[0][6:])\n",
    "\n",
    "    # increment = int(files[0].split('.xlsx')[0][6:]) + 1\n",
    "\n",
    "    for i,f in enumerate(files):\n",
    "\n",
    "        \"\"\"\n",
    "        Predicting only average ISI_out, not #Spikes_out\n",
    "        \"\"\"\n",
    "        \n",
    "        file = pd.read_excel(path + '/' + f)\n",
    "\n",
    "        cols_drop = []\n",
    "\n",
    "        for id in range(nG):\n",
    "          cols_drop.append(\"spk_ip_\" + str(id))\n",
    "          cols_drop.append(\"ISI_\" + str(id))\n",
    "\n",
    "        # cols_drop.append(\"ISI_out\")\n",
    "\n",
    "        file.drop(cols_drop, axis=1, inplace=True)\n",
    "\n",
    "        file_v1 = file.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        X_train  = file_v1.drop(labels = ['Time(s)', 'Column Number', '#Spikes_out','Avg_ISI_out', \"ISI_out\"], axis=1).values\n",
    "        y_train =  file_v1['ISI_out'].values\n",
    "\n",
    "        X_train_v1 = np.concatenate([X_train[:, :numCp*2], np.zeros((X_train.shape[0], X_train.shape[1] - (numCp*2)))], axis =1)\n",
    "        \n",
    "        if i == 0:\n",
    "          X_tr, y_tr =  X_train_v1, y_train\n",
    " \n",
    "        else:\n",
    "          X_tr1, y_tr1 =  X_train_v1, y_train\n",
    "\n",
    "          X_tr = np.concatenate([X_tr, X_tr1])\n",
    "          y_tr = np.concatenate([y_tr, y_tr1])\n",
    "\n",
    "   \n",
    "    with open(dirName + \"/X_unseen_stacked_\" + fol + \".npy\", 'wb') as f:\n",
    "      np.save(f, X_tr)\n",
    "\n",
    "    with open(dirName+\"/y_unseen_stacked_\" + fol + \".npy\", 'wb') as f:\n",
    "      np.save(f, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgfucFxO2Nz4",
    "outputId": "82b8b4ae-05d0-46c4-a868-d119cf91d933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################### Column_43 #########################\n",
      "######################### Column_19 #########################\n",
      "######################### Column_16 #########################\n",
      "######################### Column_79 #########################\n",
      "######################### Column_26 #########################\n",
      "######################### Column_30 #########################\n",
      "######################### Column_100 #########################\n",
      "######################### Column_29 #########################\n",
      "######################### Column_124 #########################\n",
      "######################### Column_97 #########################\n",
      "######################### Column_77 #########################\n",
      "######################### Column_111 #########################\n",
      "######################### Column_37 #########################\n",
      "######################### Column_33 #########################\n",
      "######################### Column_17 #########################\n",
      "######################### Column_56 #########################\n",
      "######################### Column_1 #########################\n",
      "######################### Column_81 #########################\n",
      "######################### Column_32 #########################\n",
      "######################### Column_105 #########################\n",
      "######################### Column_95 #########################\n",
      "######################### Column_99 #########################\n",
      "######################### Column_115 #########################\n",
      "######################### Column_27 #########################\n",
      "######################### Column_2 #########################\n",
      "######################### Column_34 #########################\n",
      "######################### Column_116 #########################\n",
      "######################### Column_38 #########################\n",
      "######################### Column_9 #########################\n",
      "######################### Column_104 #########################\n",
      "######################### Column_35 #########################\n",
      "######################### Column_121 #########################\n",
      "######################### Column_114 #########################\n",
      "######################### Column_31 #########################\n",
      "######################### Column_57 #########################\n",
      "######################### Column_68 #########################\n",
      "######################### Column_59 #########################\n",
      "######################### Column_94 #########################\n",
      "######################### Column_84 #########################\n",
      "######################### Column_119 #########################\n",
      "######################### Column_40 #########################\n",
      "######################### Column_122 #########################\n",
      "######################### Column_126 #########################\n",
      "######################### Column_92 #########################\n",
      "######################### Column_20 #########################\n",
      "######################### Column_24 #########################\n",
      "######################### Column_36 #########################\n",
      "######################### Column_74 #########################\n",
      "######################### Column_96 #########################\n",
      "######################### Column_6 #########################\n",
      "######################### Column_85 #########################\n",
      "######################### Column_47 #########################\n",
      "######################### Column_82 #########################\n",
      "######################### Column_22 #########################\n",
      "######################### Column_48 #########################\n",
      "######################### Column_98 #########################\n",
      "######################### Column_90 #########################\n",
      "######################### Column_41 #########################\n",
      "######################### Column_106 #########################\n",
      "######################### Column_91 #########################\n",
      "######################### Column_28 #########################\n",
      "######################### Column_72 #########################\n",
      "######################### Column_118 #########################\n",
      "######################### Column_25 #########################\n",
      "######################### Column_101 #########################\n",
      "######################### Column_109 #########################\n",
      "######################### Column_62 #########################\n",
      "######################### Column_10 #########################\n",
      "######################### Column_12 #########################\n",
      "######################### Column_60 #########################\n",
      "######################### Column_42 #########################\n",
      "######################### Column_73 #########################\n",
      "######################### Column_21 #########################\n",
      "######################### Column_64 #########################\n",
      "######################### Column_23 #########################\n",
      "######################### Column_11 #########################\n",
      "######################### Column_113 #########################\n",
      "######################### Column_89 #########################\n",
      "######################### Column_66 #########################\n",
      "######################### Column_7 #########################\n",
      "######################### Column_70 #########################\n",
      "######################### Column_61 #########################\n",
      "######################### Column_86 #########################\n",
      "######################### Column_14 #########################\n",
      "######################### Column_87 #########################\n",
      "######################### Column_15 #########################\n",
      "######################### Column_127 #########################\n",
      "######################### Column_69 #########################\n",
      "######################### Column_0 #########################\n",
      "######################### Column_52 #########################\n",
      "######################### Column_4 #########################\n",
      "######################### Column_44 #########################\n",
      "######################### Column_83 #########################\n",
      "######################### Column_102 #########################\n",
      "######################### Column_45 #########################\n",
      "######################### Column_5 #########################\n",
      "######################### Column_93 #########################\n",
      "######################### Column_88 #########################\n",
      "######################### Column_78 #########################\n",
      "######################### Column_3 #########################\n",
      "######################### Column_123 #########################\n",
      "######################### Column_75 #########################\n",
      "######################### Column_71 #########################\n",
      "######################### Column_117 #########################\n",
      "######################### Column_55 #########################\n",
      "######################### Column_120 #########################\n",
      "######################### Column_63 #########################\n",
      "######################### Column_80 #########################\n",
      "######################### Column_51 #########################\n",
      "######################### Column_110 #########################\n",
      "######################### Column_67 #########################\n",
      "######################### Column_107 #########################\n",
      "######################### Column_46 #########################\n",
      "######################### Column_53 #########################\n",
      "######################### Column_108 #########################\n",
      "######################### Column_58 #########################\n",
      "######################### Column_8 #########################\n",
      "######################### Column_50 #########################\n",
      "######################### Column_112 #########################\n",
      "######################### Column_18 #########################\n",
      "######################### Column_76 #########################\n",
      "######################### Column_103 #########################\n",
      "######################### Column_54 #########################\n",
      "######################### Column_65 #########################\n",
      "######################### Column_13 #########################\n",
      "######################### Column_39 #########################\n",
      "######################### Column_125 #########################\n",
      "######################### Column_49 #########################\n"
     ]
    }
   ],
   "source": [
    "for var1 in [(\"files_128_nominal_raw\", \"StackedFiles_nominal\")]:\n",
    "\n",
    "  dr, dirName = var1\n",
    "\n",
    "  # Saving the features and their ground truth for each column of crossbar array\n",
    "  for fol in fol_name:\n",
    "    print(\"#\" * 25 + \" \" + fol + \" \" + \"#\"*25)\n",
    "    StackedFile(os.getcwd() + '/' + dr+\"/\" + fol + \"/\", 128, fol, dirName, numCp = 48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N963AUqrxWXo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing_128by128.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
